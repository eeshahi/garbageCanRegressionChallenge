---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---

# Garbage Can Regression Challenge

**Choose R or Python and delete the other code chunk.**


## Python Code

```{python}
#| echo: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
data = {
    'Stress': [0,0,0,1,1,1,2,2,2,8,8,8,12,12,12],
    'StressSurvey': [0,0,0,3,3,3,6,6,6,9,9,9,12,12,12],
    'Time': [0,1,1,1,1,1,2,2,2,2,2,2.1,2.2,2.2,2.2],
    'Anxiety': [0,0.1,0.1,1.1,1.1,1.1,2.2,2.2,2.2,8.2,8.2,8.21,12.22,12.22,12.22]
}

observDF = pd.DataFrame(data)
print(observDF)
```

## Your Analysis

Follow the challenge instructions from your course to complete your analysis.

### 75% Questions
### 1. Bivariate Regression: Anxiety on StressSurvey

```{python}
#| echo: false
# Bivariate regression of Anxiety on StressSurvey
X = observDF[['StressSurvey']]
y = observDF['Anxiety']

# Add constant for intercept
X_with_const = sm.add_constant(X)

# Fit the regression model
model = sm.OLS(y, X_with_const).fit()

# Display results
print("Bivariate Regression Results: Anxiety ~ StressSurvey")
print("=" * 50)
print(model.summary())

# Extract coefficients
intercept = model.params['const']
slope = model.params['StressSurvey']
r_squared = model.rsquared

print(f"\nEstimated Coefficients:")
print(f"Intercept: {intercept:.4f}")
print(f"Slope (StressSurvey): {slope:.4f}")
print(f"R-squared: {r_squared:.4f}")

# True relationship: Anxiety = Stress + 0.1 × Time
print(f"\nTrue Relationship: Anxiety = Stress + 0.1 × Time")
print("Note: The true model uses 'Stress' and 'Time', not 'StressSurvey'")
```

```{python}
#| echo: false
# Compare with true relationship
print("Comparison with True Relationship:")
print("=" * 40)

# Calculate true coefficients if we were regressing Anxiety on Stress
true_stress_coef = 1.0  # Coefficient of Stress in true model
true_intercept = 0.0    # No intercept in true model (approximately)

print(f"True coefficient for Stress: {true_stress_coef}")
print(f"Estimated coefficient for StressSurvey: {slope:.4f}")
print(f"Difference: {abs(slope - true_stress_coef):.4f}")

# Check if StressSurvey is a good proxy for Stress
correlation_stress_stressurvey = observDF['Stress'].corr(observDF['StressSurvey'])
print(f"\nCorrelation between Stress and StressSurvey: {correlation_stress_stressurvey:.4f}")

# Visualize the relationship
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# Plot 1: Anxiety vs StressSurvey (what we're regressing)
ax1.scatter(observDF['StressSurvey'], observDF['Anxiety'], alpha=0.7)
ax1.plot(observDF['StressSurvey'], intercept + slope * observDF['StressSurvey'], 
         'r-', linewidth=2, label=f'Fitted line: Anxiety = {intercept:.3f} + {slope:.3f} × StressSurvey')
ax1.set_xlabel('StressSurvey')
ax1.set_ylabel('Anxiety')
ax1.set_title('Anxiety vs StressSurvey (Estimated)')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Anxiety vs Stress (true relationship)
ax2.scatter(observDF['Stress'], observDF['Anxiety'], alpha=0.7)
ax2.plot(observDF['Stress'], true_intercept + true_stress_coef * observDF['Stress'], 
         'g-', linewidth=2, label='True relationship: Anxiety = Stress + 0.1 × Time')
ax2.set_xlabel('Stress')
ax2.set_ylabel('Anxiety')
ax2.set_title('Anxiety vs Stress (True Relationship)')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

### Interpretation of Results
It fits well but is wrong, because the true model is Anxiety = Stress + 0.1·Time (intercept 0, no StressSurvey), so using the survey proxy and omitting Time biases the result.

### 2. Visualization of Bivariate Relationship

```{python}
#| echo: false
# Create detailed scatter plot with regression line
fig, ax = plt.subplots(figsize=(10, 6))

# Scatter plot
ax.scatter(observDF['StressSurvey'], observDF['Anxiety'], 
           alpha=0.7, s=100, color='steelblue', edgecolors='black', linewidth=1)

# Regression line
x_range = np.linspace(observDF['StressSurvey'].min(), observDF['StressSurvey'].max(), 100)
y_pred = intercept + slope * x_range
ax.plot(x_range, y_pred, 'r-', linewidth=3, label=f'Regression Line: Anxiety = {intercept:.3f} + {slope:.3f} × StressSurvey')

# Add data point labels for clarity
for i, row in observDF.iterrows():
    ax.annotate(f'({row["StressSurvey"]}, {row["Anxiety"]:.2f})', 
                (row['StressSurvey'], row['Anxiety']),
                xytext=(5, 5), textcoords='offset points',
                fontsize=8, alpha=0.7)

# Formatting
ax.set_xlabel('StressSurvey', fontsize=12, fontweight='bold')
ax.set_ylabel('Anxiety', fontsize=12, fontweight='bold')
ax.set_title('Bivariate Relationship: Anxiety vs StressSurvey\nwith Regression Line', 
             fontsize=14, fontweight='bold', pad=20)
ax.legend(fontsize=11, loc='upper left')
ax.grid(True, alpha=0.3)
ax.set_facecolor('#f8f9fa')

# Add regression statistics as text
stats_text = f'R² = {r_squared:.4f}\nSlope = {slope:.4f}\nIntercept = {intercept:.4f}'
ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,
        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

plt.tight_layout()
plt.show()

# Additional analysis
print("Detailed Analysis of the Bivariate Relationship:")
print("=" * 50)
print(f"Number of observations: {len(observDF)}")
print(f"Range of StressSurvey: {observDF['StressSurvey'].min()} to {observDF['StressSurvey'].max()}")
print(f"Range of Anxiety: {observDF['Anxiety'].min():.2f} to {observDF['Anxiety'].max():.2f}")
print(f"Correlation coefficient: {observDF['StressSurvey'].corr(observDF['Anxiety']):.6f}")
print(f"Standard error of residuals: {np.sqrt(model.mse_resid):.4f}")
```

### Comments on Fit and Potential Issues


